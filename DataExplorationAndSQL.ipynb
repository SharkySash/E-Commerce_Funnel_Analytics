{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### Data Cleaning --Remove NaN Values from the JSON",
   "id": "13f3b5b7ef5d443e"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "# Path to your JSON file\n",
    "file_path = r'C:\\Users\\saswa\\OneDrive\\Documents\\Puffy\\sample_events_data.json'\n",
    "# Read the JSON file into a DataFrame\n",
    "df = pd.read_json(file_path)\n",
    "# Replace all NaN with None (so that they become 'null' in JSON)\n",
    "df_clean = df.where(pd.notnull(df), None)\n",
    "# Optional: Save the cleaned version back to file (for SQL Server OPENROWSET)\n",
    "cleaned_path = r'C:\\Users\\saswa\\OneDrive\\Documents\\Puffy\\sample_events_data_clean.json'\n",
    "df_clean.to_json(cleaned_path, orient='records', indent=2)\n",
    "with open(cleaned_path, 'r') as f:\n",
    "    json_data = json.load(f)  # Will raise error if not valid\n",
    "print(\"✅ JSON is valid\")\n"
   ],
   "id": "9719e84b8129c19e",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### Connect to SQL Server",
   "id": "58224057e1c7259d"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-29T21:36:19.014958Z",
     "start_time": "2025-06-29T21:36:19.003093Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import pyodbc\n",
    "SERVER_NAME = 'Saswat\\\\SQLEXPRESS'\n",
    "DATABASE_NAME = 'msdb'  # Or the specific database you want to connect to\n",
    "connection_string = (\n",
    "    f\"DRIVER={{ODBC Driver 17 for SQL Server}};\"\n",
    "    f\"SERVER={SERVER_NAME};\"\n",
    "    f\"DATABASE={DATABASE_NAME};\"\n",
    "    f\"Trusted_Connection=yes;\"\n",
    ")\n",
    "conn = pyodbc.connect(connection_string)\n",
    "cursor = conn.cursor()\n",
    "print(\"✅ Connected to SQL Server successfully!\")"
   ],
   "id": "9bdc9843612a2a36",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Connected to SQL Server successfully!\n"
     ]
    }
   ],
   "execution_count": 71
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### Load Cleaned JSON into a Table PuffyRawDataEvents",
   "id": "4014147220928b51"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-29T21:36:19.058020Z",
     "start_time": "2025-06-29T21:36:19.046700Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# SQL query to Read the cleansed JSON and Load to an SQL Server table named PuffyRawDataEvents\n",
    "sql_query = \"\"\"\n",
    "SELECT\n",
    "    event_timestamp,\n",
    "    event_name,\n",
    "    event_previous_timestamp,\n",
    "    event_value_in_usd,\n",
    "    event_bundle_sequence_id,\n",
    "    event_server_timestamp_offset,\n",
    "    user_id,\n",
    "    user_pseudo_id,\n",
    "    traffic_source_name,\n",
    "    traffic_source_medium,\n",
    "    traffic_source_source,\n",
    "    platform,\n",
    "    JSON_VALUE(event_params, '$.ga_session_number') AS ga_session_number,\n",
    "    JSON_VALUE(event_params, '$.campaign') AS campaign,\n",
    "    JSON_VALUE(event_params, '$.content') AS content,\n",
    "    JSON_VALUE(event_params, '$.gclid') AS gclid,\n",
    "    JSON_VALUE(event_params, '$.value') AS value,\n",
    "    JSON_VALUE(event_params, '$.tax') AS tax,\n",
    "    JSON_VALUE(event_params, '$.srsltid') AS srsltid,\n",
    "    JSON_VALUE(event_params, '$.ga_session_id') AS ga_session_id,\n",
    "    JSON_VALUE(event_params, '$.session_engaged') AS session_engaged,\n",
    "    JSON_VALUE(event_params, '$.page_referrer') AS page_referrer,\n",
    "    JSON_VALUE(event_params, '$.engagement_time_msec') AS engagement_time_msec,\n",
    "    JSON_VALUE(event_params, '$.entrances') AS entrances,\n",
    "    JSON_VALUE(event_params, '$.ecomm_pagetype') AS ecomm_pagetype,\n",
    "    JSON_VALUE(event_params, '$.currency') AS currency,\n",
    "    JSON_VALUE(event_params, '$.term') AS term,\n",
    "    JSON_VALUE(event_params, '$.source') AS source,\n",
    "    JSON_VALUE(event_params, '$.ecomm_totalvalue') AS ecomm_totalvalue,\n",
    "    JSON_VALUE(event_params, '$.ecomm_prodid') AS ecomm_prodid,\n",
    "    JSON_VALUE(event_params, '$.engaged_session_event') AS engaged_session_event,\n",
    "    JSON_VALUE(event_params, '$.shipping') AS shipping,\n",
    "    JSON_VALUE(event_params, '$.medium') AS medium,\n",
    "    JSON_VALUE(event_params, '$.ignore_referrer') AS ignore_referrer,\n",
    "    JSON_VALUE(event_params, '$.transaction_id') AS transaction_id\n",
    "INTO PuffyRawDataEvents\n",
    "FROM OPENROWSET(\n",
    "    BULK 'C:\\\\Users\\\\saswa\\\\OneDrive\\\\Documents\\\\Puffy\\\\sample_events_data_clean.json',\n",
    "    SINGLE_CLOB\n",
    ") AS raw\n",
    "CROSS APPLY OPENJSON(BulkColumn)\n",
    "WITH (\n",
    "    event_timestamp bigint,\n",
    "    event_name nvarchar(100),\n",
    "    event_previous_timestamp nvarchar(100),\n",
    "    event_value_in_usd nvarchar(100),\n",
    "    event_bundle_sequence_id bigint,\n",
    "    event_server_timestamp_offset nvarchar(100),\n",
    "    user_id nvarchar(100),\n",
    "    user_pseudo_id nvarchar(100),\n",
    "    traffic_source_name nvarchar(100),\n",
    "    traffic_source_medium nvarchar(100),\n",
    "    traffic_source_source nvarchar(100),\n",
    "    platform nvarchar(100),\n",
    "    event_params nvarchar(max) AS JSON\n",
    ") AS evt;\n",
    "\"\"\"\n",
    "\n",
    "# Attempt to execute query\n",
    "try:\n",
    "    with pyodbc.connect(connection_string) as conn:\n",
    "        with conn.cursor() as cursor:\n",
    "            cursor.execute(sql_query)\n",
    "            conn.commit()\n",
    "    print(\"SQL query executed successfully.\")\n",
    "except Exception as e:\n",
    "    print(\"Error executing SQL query:\", e)\n",
    "\n"
   ],
   "id": "5dda3d7dd025fb67",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error executing SQL query: ('42S01', \"[42S01] [Microsoft][ODBC Driver 17 for SQL Server][SQL Server]There is already an object named 'PuffyRawDataEvents' in the database. (2714) (SQLExecDirectW)\")\n"
     ]
    }
   ],
   "execution_count": 72
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### Check Unique Event Names in the Dataset",
   "id": "c492e518b0b4fbc8"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-29T21:36:19.125010Z",
     "start_time": "2025-06-29T21:36:19.080217Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Let's also check what unique event names exist in the dataset\n",
    "query_events = \"\"\"\n",
    "SELECT DISTINCT event_name, COUNT(*) as event_count\n",
    "FROM PuffyRawDataEvents\n",
    "GROUP BY event_name\n",
    "ORDER BY event_count DESC\n",
    "\"\"\"\n",
    "\n",
    "try:\n",
    "    cursor.execute(query_events)\n",
    "    rows = cursor.fetchall()\n",
    "    columns = [column[0] for column in cursor.description]\n",
    "    events_df = pd.DataFrame.from_records(rows, columns=columns)\n",
    "\n",
    "    print(\"Available event types:\")\n",
    "    display(events_df)\n",
    "\n",
    "except pyodbc.Error as e:\n",
    "    print(f\"Error: {str(e)}\")"
   ],
   "id": "e48ec3e153060dd0",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Available event types:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "       event_name  event_count\n",
       "0       page_view        10056\n",
       "1       view_item         5664\n",
       "2   session_start         5431\n",
       "3     first_visit         3802\n",
       "4     add_to_cart          857\n",
       "5  begin_checkout          268\n",
       "6        purchase           88"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>event_name</th>\n",
       "      <th>event_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>page_view</td>\n",
       "      <td>10056</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>view_item</td>\n",
       "      <td>5664</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>session_start</td>\n",
       "      <td>5431</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>first_visit</td>\n",
       "      <td>3802</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>add_to_cart</td>\n",
       "      <td>857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>begin_checkout</td>\n",
       "      <td>268</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>purchase</td>\n",
       "      <td>88</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 73
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### Check the Date Range in the Dataset",
   "id": "5f6d94504f8ba41c"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-29T21:36:19.200456Z",
     "start_time": "2025-06-29T21:36:19.166413Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Check the date range in the dataset\n",
    "query_date_range = \"\"\"\n",
    "SELECT\n",
    "    MIN(CONVERT(date, DATEADD(SECOND, event_timestamp / 1000000, '1970-01-01'))) as min_date,\n",
    "    MAX(CONVERT(date, DATEADD(SECOND, event_timestamp / 1000000, '1970-01-01'))) as max_date,\n",
    "    COUNT(DISTINCT CONVERT(date, DATEADD(SECOND, event_timestamp / 1000000, '1970-01-01'))) as total_days,\n",
    "    COUNT(*) as total_events\n",
    "FROM PuffyRawDataEvents\n",
    "\"\"\"\n",
    "\n",
    "try:\n",
    "    cursor.execute(query_date_range)\n",
    "    rows = cursor.fetchall()\n",
    "    columns = [column[0] for column in cursor.description]\n",
    "    date_range_df = pd.DataFrame.from_records(rows, columns=columns)\n",
    "\n",
    "    print(\"Dataset date range:\")\n",
    "    display(date_range_df)\n",
    "\n",
    "except pyodbc.Error as e:\n",
    "    print(f\"Error: {str(e)}\")"
   ],
   "id": "f957f54dc01f1915",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset date range:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "     min_date    max_date  total_days  total_events\n",
       "0  2023-05-30  2023-06-13          15         26166"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>min_date</th>\n",
       "      <th>max_date</th>\n",
       "      <th>total_days</th>\n",
       "      <th>total_events</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2023-05-30</td>\n",
       "      <td>2023-06-13</td>\n",
       "      <td>15</td>\n",
       "      <td>26166</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 74
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### Query for Comprehensive Funnel Segment Analysis",
   "id": "af325e4fd793c68c"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-29T21:36:19.490338Z",
     "start_time": "2025-06-29T21:36:19.269153Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Comprehensive e-commerce funnel analysis query\n",
    "funnel_query = \"\"\"\n",
    "WITH daily_funnel AS (\n",
    "    SELECT\n",
    "        CONVERT(date, DATEADD(SECOND, event_timestamp / 1000000, '1970-01-01')) as event_date,\n",
    "        user_pseudo_id,\n",
    "        -- Define funnel stages based on common e-commerce events\n",
    "        MAX(CASE WHEN event_name IN ('page_view', 'session_start', 'user_engagement') THEN 1 ELSE 0 END) as visited_site,\n",
    "        MAX(CASE WHEN event_name IN ('view_item', 'product_view', 'view_item_list') THEN 1 ELSE 0 END) as viewed_product,\n",
    "        MAX(CASE WHEN event_name IN ('add_to_cart', 'add_to_wishlist') THEN 1 ELSE 0 END) as added_to_cart,\n",
    "        MAX(CASE WHEN event_name IN ('begin_checkout', 'checkout_progress', 'add_payment_info', 'add_shipping_info') THEN 1 ELSE 0 END) as initiated_checkout,\n",
    "        MAX(CASE WHEN event_name IN ('purchase', 'ecommerce_purchase', 'transaction') THEN 1 ELSE 0 END) as completed_purchase\n",
    "    FROM PuffyRawDataEvents\n",
    "    WHERE CONVERT(date, DATEADD(SECOND, event_timestamp / 1000000, '1970-01-01')) IS NOT NULL\n",
    "    GROUP BY CONVERT(date, DATEADD(SECOND, event_timestamp / 1000000, '1970-01-01')), user_pseudo_id\n",
    "),\n",
    "funnel_metrics AS (\n",
    "    SELECT\n",
    "        event_date,\n",
    "        -- Count users at each funnel stage\n",
    "        COUNT(DISTINCT user_pseudo_id) as total_users,\n",
    "        COUNT(DISTINCT CASE WHEN visited_site = 1 THEN user_pseudo_id END) as users_visited_site,\n",
    "        COUNT(DISTINCT CASE WHEN viewed_product = 1 THEN user_pseudo_id END) as users_viewed_product,\n",
    "        COUNT(DISTINCT CASE WHEN added_to_cart = 1 THEN user_pseudo_id END) as users_added_to_cart,\n",
    "        COUNT(DISTINCT CASE WHEN initiated_checkout = 1 THEN user_pseudo_id END) as users_initiated_checkout,\n",
    "        COUNT(DISTINCT CASE WHEN completed_purchase = 1 THEN user_pseudo_id END) as users_completed_purchase\n",
    "    FROM daily_funnel\n",
    "    GROUP BY event_date\n",
    ")\n",
    "SELECT\n",
    "    event_date,\n",
    "    users_visited_site as stage_1_site_visit,\n",
    "    users_viewed_product as stage_2_product_view,\n",
    "    users_added_to_cart as stage_3_add_to_cart,\n",
    "    users_initiated_checkout as stage_4_checkout,\n",
    "    users_completed_purchase as stage_5_purchase,\n",
    "\n",
    "    -- Calculate step-wise conversion rates\n",
    "    CASE\n",
    "        WHEN users_visited_site > 0\n",
    "        THEN ROUND(CAST(users_viewed_product AS FLOAT) / users_visited_site * 100, 2)\n",
    "        ELSE 0\n",
    "    END as conv_rate_visit_to_product_view,\n",
    "\n",
    "    CASE\n",
    "        WHEN users_viewed_product > 0\n",
    "        THEN ROUND(CAST(users_added_to_cart AS FLOAT) / users_viewed_product * 100, 2)\n",
    "        ELSE 0\n",
    "    END as conv_rate_product_to_cart,\n",
    "\n",
    "    CASE\n",
    "        WHEN users_added_to_cart > 0\n",
    "        THEN ROUND(CAST(users_initiated_checkout AS FLOAT) / users_added_to_cart * 100, 2)\n",
    "        ELSE 0\n",
    "    END as conv_rate_cart_to_checkout,\n",
    "\n",
    "    CASE\n",
    "        WHEN users_initiated_checkout > 0\n",
    "        THEN ROUND(CAST(users_completed_purchase AS FLOAT) / users_initiated_checkout * 100, 2)\n",
    "        ELSE 0\n",
    "    END as conv_rate_checkout_to_purchase,\n",
    "\n",
    "    -- Overall conversion rate from site visit to purchase\n",
    "    CASE\n",
    "        WHEN users_visited_site > 0\n",
    "        THEN ROUND(CAST(users_completed_purchase AS FLOAT) / users_visited_site * 100, 2)\n",
    "        ELSE 0\n",
    "    END as overall_conversion_rate\n",
    "\n",
    "FROM funnel_metrics\n",
    "WHERE event_date IS NOT NULL\n",
    "ORDER BY event_date;\n",
    "\"\"\"\n",
    "try:\n",
    "    cursor.execute(funnel_query)\n",
    "    rows = cursor.fetchall()\n",
    "    columns = [column[0] for column in cursor.description]\n",
    "    funnel_df = pd.DataFrame.from_records(rows, columns=columns)\n",
    "\n",
    "# Safe CSV saving with error handling\n",
    "    import os\n",
    "    from datetime import datetime\n",
    "\n",
    "    csv_filename = r'C:\\Users\\saswa\\OneDrive\\Documents\\Puffy\\ecommerce_funnel_analysis.csv'\n",
    "\n",
    "    try:\n",
    "        funnel_df.to_csv(csv_filename, index=False)\n",
    "        print(f\"\\n✅ Results saved to '{csv_filename}'\")\n",
    "    except PermissionError:\n",
    "        # Try alternative filename with timestamp\n",
    "        timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "        alternative_filename = f'ecommerce_funnel_analysis_{timestamp}.csv'\n",
    "        try:\n",
    "            funnel_df.to_csv(alternative_filename, index=False)\n",
    "            print(f\"\\n✅ Results saved to '{alternative_filename}' (original file was locked)\")\n",
    "        except PermissionError:\n",
    "            # Try saving to user's Documents folder\n",
    "            try:\n",
    "                documents_path = os.path.join(os.path.expanduser(\"~\"), \"Documents\")\n",
    "                fallback_filename = os.path.join(documents_path, alternative_filename)\n",
    "                funnel_df.to_csv(fallback_filename, index=False)\n",
    "                print(f\"\\n✅ Results saved to '{fallback_filename}'\")\n",
    "            except Exception as e:\n",
    "                print(f\"\\n⚠️ Could not save CSV file: {e}\")\n",
    "                print(\"Data is still available in the 'funnel_df' variable for further analysis.\")\n",
    "\n",
    "except pyodbc.Error as e:\n",
    "    print(f\"Error executing funnel query: {str(e)}\")\n"
   ],
   "id": "6ea728543280ba9a",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "✅ Results saved to 'C:\\Users\\saswa\\OneDrive\\Documents\\Puffy\\ecommerce_funnel_analysis.csv'\n"
     ]
    }
   ],
   "execution_count": 75
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-29T21:36:19.513444Z",
     "start_time": "2025-06-29T21:36:19.508537Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Calculate overall funnel summary\n",
    "if 'funnel_df' in locals() and not funnel_df.empty:\n",
    "    print(\"\\n📊 Funnel Summary Statistics:\")\n",
    "    print(f\"Total days analyzed: {len(funnel_df)}\")\n",
    "    print(f\"Average daily site visits: {funnel_df['stage_1_site_visit'].mean():.0f}\")\n",
    "    print(f\"Average overall conversion rate: {funnel_df['overall_conversion_rate'].mean():.2f}%\")\n",
    "    print(f\"Best performing day: {funnel_df.loc[funnel_df['overall_conversion_rate'].idxmax(), 'event_date']} ({funnel_df['overall_conversion_rate'].max():.2f}%)\")"
   ],
   "id": "a05eff0349c8b072",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "📊 Funnel Summary Statistics:\n",
      "Total days analyzed: 15\n",
      "Average daily site visits: 360\n",
      "Average overall conversion rate: 1.67%\n",
      "Best performing day: 2023-06-10 (3.53%)\n"
     ]
    }
   ],
   "execution_count": 76
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
